{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all packages\n",
    "import os, platform\n",
    "import subprocess\n",
    "import shutil\n",
    "import nltk\n",
    "from nltk import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "This module already contains a /pdf for all IMF Article IV files for analysis. \n",
    "I proceed by reading /pdf to new txt folder named /tmp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PROCESS PDF TO TXT\n",
    "\n",
    "# pdf files dir\n",
    "input = os.getcwd() + '\\\\pdf\\\\'\n",
    "# final dir after converted\n",
    "output = os.getcwd() + '\\\\tmp\\\\'\n",
    "# check/create if output folder exist\n",
    "if not os.path.exists(output):\n",
    "   os.makedirs(output)\n",
    "\n",
    "# process pdf to txt file save in /tmp\n",
    "# check platform system Windows/Macs\n",
    "xpdfPath = ''\n",
    "if platform.system() == 'Windows':\n",
    "     xpdfPath = os.getcwd() + '\\\\xpdfbin-win-3.04\\\\bin64\\\\'\n",
    "else:\n",
    "     xpdfPath = os.getcwd() + '\\\\xpdfbin-mac-3.04\\\\bin64\\\\'\n",
    "\n",
    "# store .pdf files from input\n",
    "doc_list = [pdf for pdf in os.listdir(input) if pdf.endswith('.pdf')]\n",
    "# iterate and process doc_list to txt file\n",
    "for doc in doc_list:\n",
    "    subprocess.call('pdftotext ' + input + doc + ' ' + output + doc.replace('.pdf', '.txt'), cwd=xpdfPath,\n",
    "                        shell=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once I have a /tmp with all txt files, I start strip out Countries' names from within \n",
    "the document to save them as file names to an actual /txt folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SET FILE NAME TO COUNTRY--YEAR\n",
    "\n",
    "# clear/retrieve txt file\n",
    "txt_list = [txt for txt in os.listdir(output) if txt.endswith('.txt')]\n",
    "newOutput = os.getcwd() + '\\\\txt\\\\'\n",
    "# iterate and process txt_list to new txt folder\n",
    "for f in txt_list:\n",
    "    fp = open(output + f)\n",
    "    fileName = ''\n",
    "    docDate = ''\n",
    "    for i, line in enumerate(fp):\n",
    "       # retrieve doc date from 1st line\n",
    "       if i == 0:\n",
    "       # print(line.replace('\\n', ''))\n",
    "          docDate = line.replace('\\n', '')\n",
    "       # retrieve doc title from range(2,4)\n",
    "       if i in range(2, 4) and 'IMF' not in line:\n",
    "          # make sure line is not an empty line\n",
    "          if line.strip():\n",
    "             fileName = line.replace('\\n', '') + '--' + docDate\n",
    "       if i > 4:\n",
    "          break\n",
    "    fp.close()\n",
    "    if not os.path.exists(newOutput):\n",
    "       os.makedirs(newOutput)\n",
    "\n",
    "    shutil.copy(output + f, newOutput + fileName + '.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the /tmp folder once copying process is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One we have the /txt folder, we can pass the txt to our nlp training model. I will start with tokenizing the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TOKENIZE WORDS FROM TXT FILE\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "txtF = os.getcwd() + '/txt/ANGOLA--February 2017.txt'\n",
    "txtF = open(txtF)\n",
    "\n",
    "# continue to expand this regex for common stop signs in document\n",
    "docStopSigns = ['\\\\n', '--', '\\'s', '...']\n",
    "\n",
    "# our stop list = English stopwords + common punctuation + docStopSigns\n",
    "stop = stopwords.words('english') + [i for i in string.punctuation] + docStopSigns\n",
    "\n",
    "# read txt file to string and loop word-to-word by word_tokenize\n",
    "# read bagOfWords to list MINUS ones from the stop list\n",
    "# finally, join list of string together making a sequences of string\n",
    "text = ' '.join( w for w in word_tokenize(txtF.read()) if w not in stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 95),\n",
       " ('0.0', 116),\n",
       " ('1', 65),\n",
       " ('1.6', 48),\n",
       " ('10', 57),\n",
       " ('2', 67),\n",
       " ('20', 57),\n",
       " ('2014', 52),\n",
       " ('2015', 88),\n",
       " ('2016', 132),\n",
       " ('2017', 95),\n",
       " ('40', 53),\n",
       " ('ANGOLA', 65),\n",
       " ('Angola', 150),\n",
       " ('BNA', 68),\n",
       " ('Debt', 46),\n",
       " ('FUND', 61),\n",
       " ('GDP', 217),\n",
       " ('IMF', 49),\n",
       " ('INTERNATIONAL', 59),\n",
       " ('In', 52),\n",
       " ('MONETARY', 59),\n",
       " ('Oil', 58),\n",
       " ('Percent', 45),\n",
       " ('The', 168),\n",
       " ('U.S.', 88),\n",
       " ('authorities', 89),\n",
       " ('balance', 73),\n",
       " ('banks', 52),\n",
       " ('debt', 105),\n",
       " ('dollar', 46),\n",
       " ('dollars', 45),\n",
       " ('domestic', 58),\n",
       " ('exchange', 119),\n",
       " ('financial', 45),\n",
       " ('fiscal', 104),\n",
       " ('foreign', 45),\n",
       " ('gross', 46),\n",
       " ('growth', 93),\n",
       " ('market', 48),\n",
       " ('non-oil', 52),\n",
       " ('oil', 100),\n",
       " ('percent', 288),\n",
       " ('policy', 59),\n",
       " ('price', 56),\n",
       " ('public', 62),\n",
       " ('rate', 136),\n",
       " ('sector', 93),\n",
       " ('shock', 52),\n",
       " ('staff', 54)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIND 50 MOST COMMON WORDS\n",
    "\n",
    "# find 50 most frequent words in the txt by FreqDist from nltk\n",
    "tokens = word_tokenize(text)\n",
    "nltkText = nltk.Text(tokens)\n",
    "\n",
    "\n",
    "fd = FreqDist(nltkText)\n",
    "common50 = fd.most_common(50)\n",
    "sorted(common50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since technical terms are usually complicated and containing multiple characters. I attempt to get rid of short words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('account', 44),\n",
       " ('angola', 215),\n",
       " ('angolan', 39),\n",
       " ('authorities', 95),\n",
       " ('average', 42),\n",
       " ('balance', 103),\n",
       " ('baseline', 44),\n",
       " ('capital', 39),\n",
       " ('central', 35),\n",
       " ('change', 43),\n",
       " ('credit', 30),\n",
       " ('currency', 48),\n",
       " ('current', 47),\n",
       " ('deficit', 30),\n",
       " ('dollar', 46),\n",
       " ('dollars', 45),\n",
       " ('domestic', 71),\n",
       " ('economic', 49),\n",
       " ('economy', 32),\n",
       " ('exchange', 142),\n",
       " ('exports', 45),\n",
       " ('external', 71),\n",
       " ('financial', 72),\n",
       " ('fiscal', 130),\n",
       " ('foreign', 68),\n",
       " ('framework', 34),\n",
       " ('government', 42),\n",
       " ('growth', 109),\n",
       " ('including', 40),\n",
       " ('increase', 44),\n",
       " ('inflation', 57),\n",
       " ('interest', 49),\n",
       " ('international', 121),\n",
       " ('investment', 31),\n",
       " ('market', 52),\n",
       " ('medium', 43),\n",
       " ('monetary', 125),\n",
       " ('non-oil', 93),\n",
       " ('percent', 333),\n",
       " ('period', 42),\n",
       " ('policy', 78),\n",
       " ('prices', 44),\n",
       " ('primary', 61),\n",
       " ('private', 35),\n",
       " ('projected', 37),\n",
       " ('public', 98),\n",
       " ('reserves', 44),\n",
       " ('revenue', 53),\n",
       " ('sector', 107),\n",
       " ('spending', 31)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if word > 5 characters\n",
    "# lowercase to prevent repeat count: exp: ANGOLA vs angola\n",
    "longCharacter = [w.lower() for w in nltkText if len(w) > 5]\n",
    "\n",
    "# Count words freq from new word list and choose most common 50\n",
    "technicalCommon50 = sorted(FreqDist(longCharacter).most_common(50))\n",
    "technicalCommon50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance adjustment revenue trade\n"
     ]
    }
   ],
   "source": [
    "nltkText.similar('deficit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
